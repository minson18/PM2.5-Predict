{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minson18/PM2.5-Predict/blob/main/PM2.5_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXhv6gO2LYkn",
        "outputId": "4de05abd-adbc-4c47-9a30-5b7da5a2787c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "# Root Path\n",
        "os.chdir('/content/drive/MyDrive/Data Mining/HW1')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = \"train.csv\"\n",
        "TEST_PATH = \"test_X.csv\""
      ],
      "metadata": {
        "id": "GaJ4NGP6pzOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ],
      "metadata": {
        "id": "rcNxN_59Q326"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean data: drop unneeded columns, replace invalid as -1\n",
        "data_df = pd.read_csv(TRAIN_PATH)\n",
        "data_df.drop(['Location             ', 'Date          ', 'ItemName                 '], axis = 1, inplace = True)\n",
        "for col in data_df.columns:\n",
        "  data_df[col] = pd.to_numeric(data_df[col], downcast=\"float\", errors='coerce').fillna(-1)\n",
        "raw_data = data_df.to_numpy()"
      ],
      "metadata": {
        "id": "GrVzLe2jRGlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform data into forms that\n",
        "# rows into continuous hours\n",
        "# columns into air pollution indices\n",
        "def transform(raw_data):\n",
        "  days = raw_data.shape[0] // 18\n",
        "  data = raw_data[0:18, :].T\n",
        "  for i in range(1, days):\n",
        "    b = raw_data[18*i:18*(i+1), :].T\n",
        "    data = np.concatenate((data, b), axis=0)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "3a6Ukjycrt5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filled invalid element by the next hour's value\n",
        "def clean(a, avg=False):\n",
        "  for i in reversed(range(a.shape[0])):\n",
        "    for j in range(a.shape[1]):\n",
        "      if a[i][j] == -1:        \n",
        "        if avg:\n",
        "          a[i][j] = np.mean(a[:, j])\n",
        "        else:\n",
        "          a[i][j] = a[i+1][j]\n",
        "  \n",
        "  return a"
      ],
      "metadata": {
        "id": "Wh807tKapjvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data by columns\n",
        "def normalize(a):\n",
        "  std = np.std(a, axis=0, dtype=np.float64)\n",
        "  mean = np.mean(a, axis=0, dtype=np.float64)\n",
        "  return (a-mean) / std"
      ],
      "metadata": {
        "id": "bHvBFHyo0dKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = transform(raw_data)\n",
        "data_avg = clean(data, avg=True)\n",
        "data_next = clean(data)"
      ],
      "metadata": {
        "id": "HQJps-f3cEjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct training data, as using last 9 hours' data \n",
        "# to predict 10'th hour PM2.5 \n",
        "def train_data(data):\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(9, data.shape[0]):\n",
        "    t = data[i-9:i, :]\n",
        "    t = t.reshape(-1)\n",
        "    X.append(t)\n",
        "    y.append([data[i, 9]])\n",
        "\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "  print(X.shape)\n",
        "  print(y.shape)\n",
        "  X = normalize(X)\n",
        "  X = np.concatenate([X , np.ones((X.shape[0],1))], axis = 1)\n",
        "\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "r7eccu--khkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_avg, y = train_data(data_avg)\n",
        "X_next, y = train_data(data_next)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5fJTAOJ4yfe",
        "outputId": "ccaa9c7c-2f47-430b-e34c-8cc2b698e2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5751, 162)\n",
            "(5751, 1)\n",
            "(5751, 162)\n",
            "(5751, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean data: drop unneeded columns, replace invalid as -1\n",
        "test_df = pd.read_csv(TEST_PATH, header = None)\n",
        "indices = test_df[0].unique()\n",
        "test_df.drop([0, 1], axis = 1, inplace = True)\n",
        "for col in test_df.columns:\n",
        "  test_df[col] = pd.to_numeric(test_df[col], downcast=\"float\", errors='coerce').fillna(0)\n",
        "raw_test = test_df.to_numpy()"
      ],
      "metadata": {
        "id": "34HEphkBpaEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = transform(raw_test)\n",
        "test_avg = clean(test, avg=True)\n",
        "test_next = clean(test)"
      ],
      "metadata": {
        "id": "hbB0eAL8rXuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct testing data, as using last 9 hours' data \n",
        "# to predict 10'th hour PM2.5 \n",
        "def test_data(test):\n",
        "  X_test = []\n",
        "  for i in range(1, test.shape[0]//9+1):\n",
        "    t = test[i*9-9:i*9, :]\n",
        "    t = t.reshape(-1)\n",
        "    X_test.append(t)\n",
        "\n",
        "  X_test = np.array(X_test)\n",
        "  print(X_test.shape)\n",
        "  X_test = normalize(X_test)\n",
        "  X_test = np.concatenate([X_test,np.ones(shape = (X_test.shape[0],1))] , axis = 1)\n",
        "\n",
        "  return X_test"
      ],
      "metadata": {
        "id": "dhzd3Q-PsNnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_avg = test_data(test_avg)\n",
        "X_test_next = test_data(test_next)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiaGUpTy6Rua",
        "outputId": "7a0cddbe-6edb-433f-d8f5-62be190bcdb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(244, 162)\n",
            "(244, 162)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find features that have correlation coefficient \n",
        "# with target larger than threshold\n",
        "def feature_select(X, X_test, threshold=0.7):\n",
        "  high_corr = []\n",
        "  for i in range(X.shape[1]):  \n",
        "    corr = np.corrcoef(X[:, i], y.reshape(-1))[0][1]\n",
        "    if abs(corr) > threshold:\n",
        "      high_corr.append(i)\n",
        "\n",
        "  return X[:, high_corr], X_test[:, high_corr]"
      ],
      "metadata": {
        "id": "Gfr5gh70rYvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find partial derivative of lossfunction\n",
        "def partial_derivative(X_batch, y_batch, m_stat):\n",
        "\n",
        "  y_pred = np.dot(X_batch, m_stat)\n",
        "  n = len(y_batch)\n",
        "  df_dm = (-2/n) * np.dot(X_batch.T, (y_batch - y_pred))\n",
        "  df_dm = df_dm.reshape(len(df_dm), -1)\n",
        "  \n",
        "  return df_dm"
      ],
      "metadata": {
        "id": "ATKF9_XBkZFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE(X, y, m_stat):\n",
        "  y_pred = np.dot(X, m_stat)\n",
        "  #print(y_pred)\n",
        "  mse = np.sum((y_pred - y)**2) / len(y)\n",
        "  \n",
        "  return mse"
      ],
      "metadata": {
        "id": "_u90UKJ5okLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(X, y, batch_size=64, lr=0.0006, epochs=3000, reg_para=1e-6, fudge_factor=0, if_print=True, random_state=None):\n",
        "  \"\"\"\n",
        "  Using linear regression and AddaGrad as optimizer\n",
        "  lr = learning rate\n",
        "  reg_para = regularization parameter\n",
        "  fudge_factor = a small number to counter numerical instabiltiy in AdaGrad\n",
        "  \"\"\"\n",
        "  if random_state is not None:\n",
        "    random.seed(random_state)\n",
        "    \n",
        "  for epoch in range(1, epochs+1):\n",
        "\n",
        "    #random initialize weight\n",
        "    if epoch == 1:\n",
        "      m_stat = np.random.rand(X.shape[1],1)\n",
        "\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    X = X[indices]\n",
        "    y = y[indices]\n",
        "    \n",
        "    cumulative_derivative = np.zeros((X.shape[1],1)) #store comulative derivative\n",
        "    for batch in range(len(X)//batch_size):\n",
        "      start = batch*batch_size\n",
        "      stop = (batch*batch_size) + batch_size\n",
        "\n",
        "      X_batch = X[start:stop]\n",
        "      y_batch = y[start:stop]\n",
        "\n",
        "      derivative = partial_derivative(X_batch, y_batch, m_stat)      \n",
        "      cumulative_derivative += derivative ** 2\n",
        "      adjusted_grad = derivative / (fudge_factor + np.sqrt(cumulative_derivative))      \n",
        "\n",
        "      #updating weight\n",
        "      m_stat = m_stat - lr*(adjusted_grad+2*reg_para*(m_stat**2))\n",
        "\n",
        "    if if_print:\n",
        "      print(f\"epoch: {epoch} ----> MSE: {MSE(X, y, m_stat)}\")\n",
        "      \n",
        "  return m_stat"
      ],
      "metadata": {
        "id": "imIeMR5ioxFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make submission file\n",
        "def submission(y_pred):\n",
        "  predictions = []\n",
        "  for i in range(len(indices)):\n",
        "    predictions.append([indices[i], y_pred[i][0]])\n",
        "  \n",
        "  # In case of colab's error, I write 2 times for ensuring\n",
        "  csv_writer = csv.writer(open('109550058.csv', 'w', newline=''))\n",
        "  csv_writer.writerow([\"index\", \"answer\"])\n",
        "  csv_writer.writerows(predictions)\n",
        "  csv_writer = csv.writer(open('109550058.csv', 'w', newline=''))\n",
        "  csv_writer.writerow([\"index\", \"answer\"])\n",
        "  csv_writer.writerows(predictions)"
      ],
      "metadata": {
        "id": "Mt4BB9Y9C3tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_stat = training(X_next, y)\n",
        "\n",
        "y_pred = (X_test_next @ m_stat) \n",
        "# Set y_pred<0 to 0\n",
        "y_pred[y_pred<0] = 0\n",
        "\n",
        "submission(y_pred)"
      ],
      "metadata": {
        "id": "z_jitTcZo04E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}